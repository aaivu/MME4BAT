# -*- coding: utf-8 -*-
"""Error_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wWTHsKshkrbF_5b5aXXRX7ZNU8XuID9U
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from datetime import datetime,date
from google.colab import files

import xgboost as xgb
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_percentage_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold

from google.colab import drive
drive.mount('/content/drive')

path= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/predicted_running_times_optimised.csv'
pred_run = pd.read_csv(path)

pred_run

pred_run['DateTime'] = pd.to_datetime(pred_run['date'] + ' ' + pred_run['start_time'])
ref_freq = '15min'
ix = pd.DatetimeIndex(pd.to_datetime(pred_run['DateTime'])).floor(ref_freq)
pred_run["DateTimeRef"] = ix

path_convlstm_out= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/convlstm_median.csv'

med_convlstm = pd.read_csv(path_convlstm_out)

med_convlstm = med_convlstm.set_index('Datetime')
med_convlstm.index = pd.to_datetime(med_convlstm.index)

date_list = med_convlstm.index.tolist()
pred_run= pred_run[pred_run['DateTimeRef'].isin(date_list)]

pred_run['med_convlstm'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DateTimeRef'] 
    pred_run.at[row_index,'med_convlstm'] = med_convlstm[str(float(segment))].loc[date_time]

pred_run

print('results for med_convlstm:')
rmse = np.sqrt(mean_squared_error(pred_run['run_time_in_seconds'], pred_run['med_convlstm'])) 

print("RMSE (1): %f" % (rmse))

mape = mean_absolute_percentage_error(pred_run['run_time_in_seconds'],pred_run['med_convlstm'])
print("MAPE (1): %f" % (mape)) 

mae = mean_absolute_error(pred_run['run_time_in_seconds'], pred_run['med_convlstm'])
print("MAE (1): %f" % (mae)) 


r2 = r2_score(pred_run['run_time_in_seconds'], pred_run['med_convlstm'])
print("r2 (1): %f" % (r2))

path_convlstm_out= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/convlstm_with_outiers.csv'

out_convlstm = pd.read_csv(path_convlstm_out)

out_convlstm = out_convlstm.set_index('Datetime')
out_convlstm.index = pd.to_datetime(out_convlstm.index)

date_list = out_convlstm.index.tolist()
pred_run= pred_run[pred_run['DateTimeRef'].isin(date_list)]

pred_run['out_convlstm'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DateTimeRef'] 
    pred_run.at[row_index,'out_convlstm'] = out_convlstm[str(float(segment))].loc[date_time]

pred_run

path_convlstm_out= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/ES_convlstm.csv'

es_convlstm = pd.read_csv(path_convlstm_out)

es_convlstm = es_convlstm.set_index('Datetime')
es_convlstm.index = pd.to_datetime(es_convlstm.index)

date_list = es_convlstm.index.tolist()
pred_run= pred_run[pred_run['DateTimeRef'].isin(date_list)]

pred_run['es_convlstm'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DateTimeRef'] 
    pred_run.at[row_index,'es_convlstm'] = es_convlstm[str(float(segment))].loc[date_time]

pred_run

print('results for es_convlstm:')
rmse = np.sqrt(mean_squared_error(pred_run['run_time_in_seconds'], pred_run['es_convlstm'])) 

print("RMSE (1): %f" % (rmse))

mape = mean_absolute_percentage_error(pred_run['run_time_in_seconds'],pred_run['es_convlstm'])
print("MAPE (1): %f" % (mape)) 

mae = mean_absolute_error(pred_run['run_time_in_seconds'], pred_run['es_convlstm'])
print("MAE (1): %f" % (mae)) 


r2 = r2_score(pred_run['run_time_in_seconds'], pred_run['es_convlstm'])
print("r2 (1): %f" % (r2))

path_convlstm_out= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/ES_convlstm_bfill.csv'

ES_convlstm_bfill = pd.read_csv(path_convlstm_out)

ES_convlstm_bfill = ES_convlstm_bfill.set_index('Datetime')
ES_convlstm_bfill.index = pd.to_datetime(ES_convlstm_bfill.index)

date_list = ES_convlstm_bfill.index.tolist()
pred_run= pred_run[pred_run['DateTimeRef'].isin(date_list)]

pred_run['ES_convlstm_bfill'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DateTimeRef'] 
    pred_run.at[row_index,'ES_convlstm_bfill'] = ES_convlstm_bfill[str(float(segment))].loc[date_time]

pred_run

print('results for ES_convlstm_bfill:')
rmse = np.sqrt(mean_squared_error(pred_run['run_time_in_seconds'], pred_run['ES_convlstm_bfill'])) 

print("RMSE (1): %f" % (rmse))

mape = mean_absolute_percentage_error(pred_run['run_time_in_seconds'],pred_run['ES_convlstm_bfill'])
print("MAPE (1): %f" % (mape)) 

mae = mean_absolute_error(pred_run['run_time_in_seconds'], pred_run['ES_convlstm_bfill'])
print("MAE (1): %f" % (mae)) 


r2 = r2_score(pred_run['run_time_in_seconds'], pred_run['ES_convlstm_bfill'])
print("r2 (1): %f" % (r2))

path_convlstm_out= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/ES_purelstm_med.csv'

ES_purelstm_med = pd.read_csv(path_convlstm_out)

ES_purelstm_med = ES_purelstm_med.set_index('Datetime')
ES_purelstm_med.index = pd.to_datetime(ES_purelstm_med.index)

date_list = ES_purelstm_med.index.tolist()
pred_run= pred_run[pred_run['DateTimeRef'].isin(date_list)]

pred_run['ES_purelstm_med'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DateTimeRef'] 
    pred_run.at[row_index,'ES_purelstm_med'] = ES_purelstm_med[str(float(segment))].loc[date_time]

pred_run

print('results for ES_purelstm_med:')
rmse = np.sqrt(mean_squared_error(pred_run['run_time_in_seconds'], pred_run['ES_purelstm_med'])) 

print("RMSE (1): %f" % (rmse))

mape = mean_absolute_percentage_error(pred_run['run_time_in_seconds'],pred_run['ES_purelstm_med'])
print("MAPE (1): %f" % (mape)) 

mae = mean_absolute_error(pred_run['run_time_in_seconds'], pred_run['ES_purelstm_med'])
print("MAE (1): %f" % (mae)) 


r2 = r2_score(pred_run['run_time_in_seconds'], pred_run['ES_purelstm_med'])
print("r2 (1): %f" % (r2))



path_convlstm_out= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/purelstm_med.csv'

purelstm_med = pd.read_csv(path_convlstm_out)

purelstm_med = purelstm_med.set_index('Datetime')
purelstm_med.index = pd.to_datetime(purelstm_med.index)

date_list = purelstm_med.index.tolist()
pred_run= pred_run[pred_run['DateTimeRef'].isin(date_list)]

pred_run['purelstm_med'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DateTimeRef'] 
    pred_run.at[row_index,'purelstm_med'] = purelstm_med[str(float(segment))].loc[date_time]

pred_run

print('results for purelstm_med:')
rmse = np.sqrt(mean_squared_error(pred_run['run_time_in_seconds'], pred_run['purelstm_med'])) 

print("RMSE (1): %f" % (rmse))

mape = mean_absolute_percentage_error(pred_run['run_time_in_seconds'],pred_run['purelstm_med'])
print("MAPE (1): %f" % (mape)) 

mae = mean_absolute_error(pred_run['run_time_in_seconds'], pred_run['purelstm_med'])
print("MAE (1): %f" % (mae)) 


r2 = r2_score(pred_run['run_time_in_seconds'], pred_run['purelstm_med'])
print("r2 (1): %f" % (r2))

pred_run['DayOfWeek'] = pd.to_datetime(pred_run['date']).dt.weekday
pred_run["DowTimeRef"] = pd.to_datetime((pred_run['DayOfWeek'].values ) * 24 * 60 * 60 + ix.hour * 60 * 60 + ix.minute * 60, unit = 's')

pred_run

path_HA= '/content/drive/Shareddrives/MSc - Shiveswarran/Predicted values/HA.csv'

HA = pd.read_csv(path_HA)

HA = HA.set_index('Datetime')
HA.index = pd.to_datetime(HA.index)

date_list = HA.index.tolist()

HA

pred_run['HA'] =''

for segment, group in pred_run.groupby('segment'):
  for row_index, row in group.iterrows():
    date_time = row['DowTimeRef'] 
    pred_run.at[row_index,'HA'] = HA.loc[date_time,str(float(segment))]

pred_run

print('results for HA:')
rmse = np.sqrt(mean_squared_error(pred_run['run_time_in_seconds'], pred_run['HA'])) 

print("RMSE (1): %f" % (rmse))

mape = mean_absolute_percentage_error(pred_run['run_time_in_seconds'],pred_run['HA'])
print("MAPE (1): %f" % (mape)) 

mae = mean_absolute_error(pred_run['run_time_in_seconds'], pred_run['HA'])
print("MAE (1): %f" % (mae)) 


r2 = r2_score(pred_run['run_time_in_seconds'], pred_run['HA'])
print("r2 (1): %f" % (r2))

def download_csv(data,filename):
  filename= filename + '.csv'
  data.to_csv(filename, encoding = 'utf-8-sig',index= False)
  files.download(filename)

download_csv(pred_run,'predicted_running_times')

trip = pred_run[pred_run['trip_id']==25360]

trip

trip = pred_run[pred_run['trip_id']==25340]

plt.figure(figsize=(15,10))
plt.plot(trip['segment'],trip['run_time_in_seconds'],label='Actual')
plt.plot(trip['segment'],trip['convlstm'],label='conv_lstm')
#plt.plot(trip['segment'],trip['out_convlstm'],label='out_convlstm')
plt.plot(trip['segment'],trip['XGBoost'],label='XGBoost')
#plt.plot(trip['segment'],trip['LightGBM'],label='LightGBM')
#plt.plot(trip['segment'],trip['cnn_lstm'],label='LSTM')
#plt.plot(trip['segment'],trip['HA'],label='HA')

plt.legend()
plt.show()

pred_run.columns

data_melted = pd.melt(pred_run, id_vars=['time_of_day'], value_vars=['XGBoost', 'convlstm', 'run_time_in_seconds'],
                      var_name='Models', value_name='Predicted run times')

data_melted

sns.set(rc={'figure.figsize':(15,10)})

sns.set_theme(style="darkgrid")
h = sns.lineplot(data=data_melted, x='time_of_day', y='Predicted run times', hue= 'Models',markers = True, style = 'Models')
h = h.set_xticks(range(6,19))
plt.xlabel("Time of Day")
plt.ylabel("Run time (seconds)")
plt.savefig('Model comparision')
plt.show()